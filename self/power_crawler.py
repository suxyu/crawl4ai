#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Power Web Crawler for KKDaxue
专门用于爬取 kkdaxue.com 上所有展开按钮的爬虫
"""

import asyncio
import sys
import os
import uuid
from datetime import datetime
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, BrowserConfig


majors = ["应用英语","啦啦啦","计算机科学与技术","软件工程","汉语言文学","英语","临床医学","土木工程","机械设计制造及其自动化","法学","电气工程及其自动化","会计学","电子信息工程","通信工程","电子商务","自动化","数学与应用数学","学前教育","工商管理","市场营销","视觉传达设计","软件技术","国际经济与贸易","生物科学","金融学","物流管理","财务管理","计算机应用技术","物联网工程","数据科学与大数据技术","历史学","物理学","护理学","信息管理与信息系统","材料科学与工程","药学","小学教育","中医学","应用化学","经济学","环境设计","建筑学","应用心理学","车辆工程","旅游管理","机械工程","工程造价","化学工程与工艺","人力资源管理","数字媒体技术","商务英语","环境工程","能源与动力工程","计算机网络技术", "人力资源管理",
"数字媒体技术",
"商务英语",
"环境工程",
"能源与动力工程",
"计算机网络技术",
"网络工程",
"生物技术",

"化学",
"食品科学与工程",
"地理科学",
"工业设计",
"数字媒体",
"艺术",
"机械电子工程",

"口腔医学",
"行政管理",
"机电一体化技术",
"工程管理",
"光电信息科学与工程",
"汉语国际教育",

"新闻学",
"给排水科学与工程",
"动画",
"动物医学",
"社会工作",
"材料成型及控制工程",
"生物工程",

"生物医学工程",
"应用物理学",
"广告学",
"思想政治教育",
"制药工程",
"医学影像技术",

"电子科学与技术",
"环境艺术设计",
"会计",
"信息与计算科学",
"建筑工程技术",
"网络与新媒体",

"土地资源管理",
"交通运输",
"公共事业管理",
"电子信息科学与技术",
"医学检验技术",
"中药学",

"高分子材料与工程",
"广播电视编导",
"护理",
"物联网应用技术",
"音乐学",
"风景园林",
"测控技术与仪器",

"测控技术与仪器",
"日语",
"社会学",
"产品设计",
"动物科学",
"心理学",
"康复治疗学",

"园林",
"播音与主持艺术",
"安全工程",
"测绘工程",
"园艺",
"人工智能",

"交通工程",
"地理信息科学",
"针灸推拿学",
"生态学",
"预防医学",
"教育技术学",
"人文地理与城乡规划",

"工业工程",
"信息安全",
"智能科学与技术",
"美术学",
"哲学",
"体育教育",

"机器人工程",
"采矿工程",
"动漫制作技术",
"广播电视学",
"城乡规划",
"云计算技术与应用",

"建筑环境与能源应用工程",
"汽车检测与维修技术",
"酒店管理",
"应用统计学",
"水产养殖学",
"统计学",
"戏剧影视文学",

"服装与服饰设计",
"大数据与会计",
"农学",
"微电子科学与工程",
"文化产业管理",
"航海技术",
"中西医临床医学",
"劳动与社会保障",
"农业资源与环境",
"环境科学",
"新能源科学与工程",
"过程装备与控制工程",

"工程力学",
"电子信息",
"音乐表演",
"金融工程",
"船舶与海洋工程",
"地质学",

"水利水电工程",
"德语",
"翻译",
"数字媒体应用技术",
"食品质量与安全",
"机械制造与自动化",
"新能源汽车技术",
"大数据管理与应用",
"绘画",
"金属材料工程",
"传播学",
"工业机器人技术",
"植物保护",

"医学影像学",
"教育学",
"林学",
"保险学",
"网络空间安全",
"税收学",

"会展经济与管理",
"无机非金属材料工程",
"秘书学",
"俄语",
"模具设计与制造",
"海洋科学",
"道路桥梁与渡河工程",
"飞行器设计与工程",
"材料与化工",
"数控技术",
"大数据技术",
"资源勘查工程",
"审计学",
"电子信息工程技术",
"汽车服务工程",
"冶金工程",
"电气工程",
"智能制造工程",
"健康服务与管理",

"飞行器制造工程",
"投资学",
"地质工程",
"侦查学",
"无人机应用技术",
"财政学",
"大数据技术与应用",
"国际商务",
"纺织工程",
"飞行技术",
"经济与金融",
"农林经济管理",

"法律",
"材料化学",
"康复治疗技术",
"大气科学",
"艺术设计",
"服装设计与工程",
"政治学与行政学",

"药物制剂",
"轨道交通信号与控制",
"包装工程",
"飞行器动力工程",
"法语",
"运动康复",

"治安学",
"信息安全技术应用",
"特殊教育",
"遥感科学与技术",
"畜牧兽医",
"基础医学",

"新能源材料与器件", 
"生物学",
"道路桥梁工程技术",
"建筑电气与智能化",
"应用电子技术",
"生物制药",

"经济统计学",
"管理科学与工程",
"环境科学与工程",
"石油工程",
"法医学",
"建筑室内设计",
"新闻与传播",

"信息工程",
"工商企业管理",
"建筑与土木工程",
"室内艺术设计",
"物业管理",
"机械",

"化学工程",
"数字媒体艺术设计",
"知识产权",
"港口航道与海岸工程",
"移动应用开发",
"公共管理",

"核工程与核技术",
"勘查技术与工程",
"铁道机车",
"轻化工程",
"影视动画",
"麻醉学",

"工艺美术",
"集成电路设计与集成系统",
"市政工程技术",
"航空航天工程",
"物流工程",
"书法学",
"朝鲜语",

"宝石及材料工艺学",
"金融",
"运动训练",
"少数民族预科班",
"文物与博物馆学",
"资产评估",

"资产评估",
"轮机工程",
"中国少数民族语言文学",
"工程测量技术",
"控制科学与工程",
"电气自动化技术",
"能源化学工程",

"地质资源与地质工程",
"飞机机电设备维修",
"生物化学与分子生物学",
"消防工程",
"雕塑",
"电气自动化",

"舞蹈表演", 
"生物信息学",
"农业水利工程",
"新闻采编与制作",
"汽车制造与装配技术",
"幼儿发展与健康管理",
"智能建造",

"外国语言文学",
"食品卫生与营养学",
"卫生检验与检疫",
"艺术与科技",
"焊接技术与工程",


"家政学",
"移动互联应用技术",
"金融数学",
"中药资源与开发",
"计算机信息管理",
"空中乘务",

"网络安全与执法",
"环境生态工程",
"设施农业科学与工程",
"连锁经营管理",
"信息与通信工程",
"油气储运工程",

"通信技术",
"会展策划与管理",
"刑事侦查",
"城市地下空间工程",
"影视编导",
"临床药学",
"艺术管理",

"听力与言语康复学",
"铁道信号自动控制",
"工程机械运用技术",
"建筑设计",
"影视摄影与制作",
"虚拟现实应用技术",

"监狱学",
"编辑出版学",
"海洋技术",
"农业机械化及其自动化",
"国际政治",
"语文教育",

"农村区域发展",
"档案学",
"考古学",
"休闲体育",
"会计电算化",
"水利水电建筑工程",


"仪器科学与技术",
"地球物理学",
"建筑工程",
"社会体育指导与管理",
"数字经济",
"现代物流管理",
"科学教育",

"材料物理",
"轮机工程技术",
"结构工程",
"城市轨道车辆应用技术",
"动画设计",
"城市轨道交通机电技术",

"金融管理",
"世界史",
"电子与通信工程",
"音乐教育",
"英语口译",
"计算机科学",

"汽车服务与营销",
"心理健康教育",
"戏剧影视表演",
"中医内科学",
"设计学",
"机械设计",

"广告艺术设计",
"材料工程",
"控制工程",
"新闻传播学",
"土木水利",
"草业科学",
"运动人体科学",

"摄影",
"储能科学与工程",
"体育",
"酿酒工程",
"中医康复技术",
"安全技术与管理",

"化学工程与技术",
"烹饪与营养教育",
"交通运输工程",
"种子科学与工程",
"刑事科学技术",
"资源与环境",


"医学营养",
"商务日语",
"水文与水资源工程",
"质量管理工程",
"烟草",
"光学工程",

"制冷与空调技术",
"茶学",
"城市轨道交通工程技术",
"矿物加工工程",
"健康管理",
"药品生产技术",
"助产学",


"医学信息工程",
"信息资源管理",
"工业工程与管理",
"园艺技术",
"金融科技",
"铁道车辆",

"司法信息安全",
"口腔医学技术",
"动车组检修技术",
"热能与动力工程",
"网络新闻与传播",
"分析化学",

"公安管理学",
"电梯工程技术",
"铁道交通运营管理",
"发电厂及电力系统",
"材料成型与控制技术",
"阿拉伯语",

"旅游管理与服务教育",
"园林技术",
"美术",
"眼视光技术",
"高分子材料科学与工程",
"现代教育技术",
"烹饪工艺与营养",

"酒店管理与数字化运营",
"应用韩语",
"基础心理学",
"区域经济学",
"广播影视节目制作",
"中国史",

"英语教育",
"戏剧影视导演",
"物理化学",
"木材科学与工程",
"建筑装饰工程技术",
"数学",

"葡萄与葡萄酒工程",
"老年保健与管理",
"动力工程及工程热物理",
"动物营养与饲料科学",
"有机化学",
"物流工程技术",

"功能材料",
"环保设备工程",
"船舶电子电气工程",
"中西医结合",
"高速铁道工程技术",
"应用数学",
"互联网金融",

"互联网金融",
"供热通风与空调工程技术",
"体育经济与管理",
"能源动力",
"自然地理与资源环境",
"休闲服务与管理",
"马克思主义理论",

"地图学与地理信息系统",
"现代通信技术",
"材料学",
"微电子技术",
"农艺与种业",
"艺术教育",

"通信工程设计与监理",
"汽车运用与维修技术",
"智能控制技术",
"投资与理财",
"内科学",
"风景园林设计",

"生物与医药",
"房地产开发与管理",
"中药制药",
"计算机网络",
"民族学",
"机械设计与制造",
"智能电网信息工程",


"森林工程",
"中医骨伤科学",
"医学实验技术",
"国际金融",
"农村发展",
"建筑环境与设备工程",

"船舶工程技术",
"水利工程",
"学科教学(英语)",
"摄影测量与遥感技术",
"文化遗产",
"美术教育",

"人文教育",
"基础数学",
"发展与教育心理学",
"老年服务与管理",
"针灸推拿",
"儿科学",


"理论与应用力学",
"流行病与卫生统计学",
"教育管理",
"现代纺织技术",
"生物医药",
"计算机技术",
"有色冶金技术",

"复合材料与工程",
"导航工程",
"信号与信息处理",
"海洋资源与环境",
"精神医学", 
"林业",

"情报学",
"电子与计算机工程",
"消防工程技术",
"光电子信息与技术",
"空间信息与数字技术",
"电信工程及管理",
"广告设计与制作",
"中西面点工艺",
"涉外警务",
"工业设计工程",
"陶瓷艺术设计",
"公共艺术",

"信息安全与管理",
"电子应用技术",
"SQA国际本科",
"管理科学",
"高速铁路客运乘务",
"游戏设计",
"法语语言文学",

"海关管理",
"印地语",
"漫画",
"动画制作技术",
"日语笔译",
"表演",

"西班牙语",
"茶叶生产与加工技术",
"康复医学与理疗学",
"交通运输管理与规划",
"食品科学",
"地球化学",

"地球化学",
"体能训练",
"供用电技术",
"眼视光医学",
"企业管理",
"产业经济学",
"光源与照明",

"贸易经济",
"建筑电气工程技术",
"临床兽医学",
"植物科学与技术",
"神经生物学",
"仪器仪表工程",
"微电子学与固体电子学",

"文秘",
"包装策划与设计",
"应用化工",
"中国古典文献学",
"外交学",
"计算机软件开发",

"戏剧影视美术设计",
"森林保护",
"应急技术与管理",
"畜牧学",
"农业建筑环境与能源工程",
"数理基础科学",

"信用管理",
"建筑设备工程技术",
"水文与工程地质",
"资源环境科学",
"控制理论与控制工程",
"机电设备维修与管理",

"汽修检测与维修技术",
"资源利用与植物保护",
"智能医学工程",
"英语笔译",
"图书馆学",
"城市轨道交通供配电技术",
"热能工程",

"作物学",
"给排水工程技术",
"建设工程监理",
"果树学",
"视觉传播设计与制作",
"科学技术哲学",

"中草药栽培与鉴定",
"希腊语",
"医学美容技术",
"意大利语",
"纺织材料与纺织品设计",
"医学遗传学",

"商务管理",
"英语+西班牙语",
"艺术学理论",
"电气工程与智能控制",
"高压输配电线路施工运行与维护",
"食品检验检测技术",

"应用气象学",
"商务经济学",
"法律文秘",
"农业管理",
"国际关系",
"医疗器械维护与管理",
"建筑智能化工程技术",

"野生动物与自然保护区管理",
"中药制药技术",
"汽车检测与维修",
"家具设计与工程",
"交通管理",
"警务指挥与战术",

"初等教育",
"城市轨道交通运营管理",
"农业电气化",
"服装设计与工艺",
"动漫设计",
"服装艺术设计",

"防灾减灾科学与工程",
"国际组织与全球治理",
"艺术管理演唱",
"商务数据分析与应用",
"应急管理",
"探测制导与控制技术",

"艺术设计学",
"司法警务",
"人工智能技术应用",
"药事管理",
"电力系统自动化技术",
"婴幼儿托育服务与管理",
"铁道供电技术",

"应用电子技术教育",
"葡萄牙语",
"新媒体技术",
"学科教学(物理)",
"学科教学(历史)",
"社会医学与卫生事业管理",

"市政工程",
"飞机电子设备维修",
"国际邮轮乘务管理",
"消防工程(应急救援方向)",
"应用经济学",
"城市管理",

"航空飞行与指挥",
"智能焊接技术",
"电子信息类",
"应用化工技术",
"历史建筑保护工程",
"石油化工技术",

"石油化工技术",
"电子商务及法律",
"蒙医学",
"信息技术",
"经济",
"舞蹈编导",
"视觉开发",
"嵌入式技术与应用",

"涉外护理",
"有机合成",
"粮食工程",
"量子计算",
"化工生物技术",
"现代模具制造",

"数学统计",
"旅游英语",
"电子与电气工程",
"建筑动画技术",
"航空弹药技术与指挥",
"航空电气工程及其自动化",

"汽车电子技术",
"建筑工程检测技术",
"统计",
"环境与设备工程",
"医学生物技术",
"专业会计",

"汉语",
"计算机信息技术",
"小儿内科",
"电子商务+电子工程",
"物理电子学",
"天文学",
"关务与外贸服务",

"声像工程技术",
"电气与信息工程",
"助产",
"草学",
"舞蹈学",
"音乐与舞蹈学",

"公共卫生",
"芯片开发",
"职业卫生工程",
"课程与教学论",
"世界经济",
"环境监测技术",

"岩土工程",
"计算机辅助设计与制造",
"污染修复与生态工程技术",
"燃料电池",
"文典学院人文科学试验班",
"药物分析",


"系统理论",
"信息系统管理",
"飞行器制造技术",
"生物医学信息学",
"保险",
"凝聚态物理",
"铁道机车车辆制造与维护",

"金融法",
"汽车智能技术",
"高分子材料加工技术",
"税务",
"高尔夫球运动与管理",
"城市与区域规划",

"应用日语",
"国际关系和公共管理",
"文物鉴定与修复",
"金融学+应用数学",
"理化测试与质检技术",
"歌剧美声演唱",

"精密医疗器械技术",
"海洋机器人",
"生物与数学",
"人文地理学",
"中医妇科学",
"计算机网络安全",

"基因与基因组",
"法学+英语",
"社会学+世界古代史",
"空间科学与技术",
"冶金材料",
"宪法学",
"日语+软件工程",

"职业技术教育",
"光学电子科学与技术",
"民航安全技术管理",
"生物技术与食品工程",
"现代农业技术", 
"计算机科学与智能系统",

"植物检疫与农业生态健康",
"历史教育",
"妇幼保健医学",
"测量学",
"药品质量与安全",
"商业经济学",

"导航、制导与控制",
"城市设计",
"智能机器人技术及应用",
"英语教育与语言研究",
"新一代电子信息技术",
"民俗学",

"石油工程技术",
"粒子物理与原子核物理",
"心理学与心理健康",
"舞蹈艺术",
"免疫学",
"药物化学",
"光子学",

"军事学",
"审计",
"物理教育",
"社工工作",
"海洋资源开发技术",
"光伏材料加工与应用技术",

"微生物学",
"刑事执行",
"大地测量学与测量工程",
"交互设计",
"机场运行服务与管理",
"应用社会学",

"电线电缆制造技术",
"壁画",
"设计工学",
"水路运输与海事管理",
"武器发射工程", 
"蜂学",

"航空发动机制造工程",
"价值链管理",
"包装工程技术",
"自动化生产设备应用",
"理论物理",
"俄语口译",
"泰语",

"储能材料技术",
"制冷及低温工程",
"国际贸易实务",
"草坪科学与工程",
"戏剧影视文学+广播电视编导",
"矿物资源工程",

"林业工程",
"商科",
"皮肤病与性病学",
"海洋生物学",
"语言学及应用语言学",
"超声医学",

"飞机维修",
"城市与区域发展",
"历史文献学",
"移动通信技术",
"工程热物理",
"可持续发展",

"农业水土工程",
"航天工程",
"食品营养与健康",
"国际经济与商法",
"农村与区域发展",
"航空电子设备维修",
"公安视听技术",

"印度尼西亚语",
"工业分析与检验",
"金属材料与热处理技术",
"乌克兰语",
"中国画",
"营养与食品卫生学",

"国际政治经济",
"神经病学",
"音乐科技与艺术",
"无机化学",
"创业与创新，市场",
"马克思主义基本原理",

"粮油储藏与检测",
"人力资源管理与劳动关系",
"古建筑工程技术",
"生产技术",
"食品营养与检测",
"教育",

"计算机通信",
"分子科学与工程",
"非洲史",
"应用分析",
"口腔正畸学",
"资源勘察工程",
"古生物学",

"有色金属智能冶金技术",
"农业工程",
"音乐剧",
"企业艺术设计",
"肿瘤学",
"房地产经营与估价",

"长空创新班",
"生理学、运动科学与营养学",
"自然资源学",
"化学工艺",
"港口与航运管理",
"水利水电工程技术",

"辐射防护与核安全",
"动物学",
"出版",
"光电信息工程",
"水声工程",
"数据科学",

"区块链技术应用",
"制药化学",
"电影学",
"精细化工",
"国际法学",
"飞机发动机",
"海洋化学",

"社区管理与服务",
"汉语言",
"安全科学与工程",
"保密技术",
"航空宇航推进理论与工程",
"农业经济管理",

"渔业发展",
"社会科学试验班",
"医学英语",
"政治学理论",
"光信息科学与技术",
"农业昆虫与害虫防治",

"融媒体技术与运营",
"邮政工程",
"预科",
"纳米科学与技术",
"电子商务新媒体运营",
"工学",

"矿物学、岩石学和矿床学",
"会计与金融分析",
"矿山机电",
"光学",
"矿井建设",
"手语翻译",
"社会科学交叉学科学习",

"社区矫正",
"文学研究科",
"语言学",
"运筹学与控制论",
"能源与动力",
"空间工程",

"国民经济管理",
"材料物理与化学",
"城市轨道交通车辆制造与...",
"工网创新",
"宝玉石鉴定与加工",
"石油化工生产技术",

"油画",
"人类学",
"法学院",
"动画交互媒体",
"安全防范技术",
"公安政治工作",

"体育康复",
"地球探测与信息技术",
"森林学",
"比较文学与世界文学",
"戏剧学",
"家具设计与制造",

"版面编辑与校对",
"数字出版",
"翻译学",
"时装设计",
"食品营养",
"酿酒技术",
"林产化工",

"电气控制及其自动化",
"公路工程管理",
"司法信息技术",
"智能终端技术与应用",
"计算机应用工程",
"海事管理",

"雷达工程",
"步兵指挥边防",
"网络空间安全执法技术",
"飞行器维修技术",
"道路与铁道工程",
"精密仪器及机械",

"汉语言文字学",
"首饰设计与工艺",
"国际关系与世界历史",
"室内设计",
"中国哲学",
"表演艺术",
"公共卫生学院",

"中医医史文献",
"建筑装饰材料技术",
"风力发电工程技术",
"高铁乘务",
"高等教育学",
"科技体育经济学",

"数字化设计与制造技术",
"核化工与核燃料工程",
"海洋渔业科学与技术",
"大数据与财务管理",
"建筑装饰与施工技术",
"绿色食品生产与检验",

"计量经济学",
"资源勘查工程+通信工程",
"国际贸易",
"商业分析",
"会计与金融",
"营养和食品管理",

"装配式建筑工程技术",
"实验艺术",
"法医学+法学",
"环境监测与控制技术",
"水土保持与荒漠化防治",
"建设工程管理",
"戏剧教育",

"印刷技术",
"创新学",
"服装表演与设计",
"核科学与核技术",
"戏剧与影视学",
"材料工程技术",

"詹天佑学院",
"民航运输",
"跨境电子商务",
"火灾勘察",
"文物与博物馆",
"移动商务",

"园林工程技术",
"工程学",
"钢琴调律",

"地理空间信息工程",
"信息对抗技术",
"航空服务",
"药品经营与管理",
"物资采购与管理",
"广播电视艺术学",

"冰雪运动与管理",
"飞行器控制与信息工程",
"法学+金融",
"法学+金融学",
"舞台灯光设计",
"文物修复与保护",
"统计与会计核算",

"刑事侦查技术",
"新媒体艺术",
"工业工程技术",
"药品生物技术",
"金融服务与管理",
"应用泰语",

"电磁场与无线技术",
"工业过程自动化技术",
"政治学与行政学+新闻学",
"信息系统",
"气象学",
"金融管理与实务",

"学科教学(美术)",
"学科教学(语文)",
"学科教学(地理)",
"学科教学(生物)",
"首饰设计",
"油料储运工程",
"报关与国际货运",

"轨道交通电气与控制",
"数学媒体应用技术",
"广播电视",
"航空运营管理",
"民航空中安全保卫",
"眼视光学",

"反恐警务",
"能源与环境系统工程",
"交通设备与控制工程",
"水务工程",
"机械工艺技术",
"舞台艺术设计与制作",

"财务会计教育",
"制药科学",
"公安学",
"司法警察学",
"电子竞技运动与管理",
"乌尔都语",

"假肢矫形工程",
"电脑艺术设计",
"早期教育",
"供应链管理",
"智慧景区开发与管理",
"中医康复学",
"小学语文教育",

"军队指挥学",
"应用俄语",
"古典文献学",
"人工智能技术服务",
"大数据与智能工程",
"国学",

"水质科学与技术",
"体育运营与管理",
"艺术品鉴定与艺术市场",
"研学旅行管理与服务",
"汽车维修工程教育",
"标准化工程",

"工业与民用建筑",
"地质类",
"化妆品技术与管理",
"哈萨克语",
"钢铁智能冶金技术",
"农业工程与信息技术",

"智慧牧业科学与工程",
"计算机应用与管理",
"应用心理",
"智慧海洋技术",
"公共关系学",
"菌物科学与工程",
"科学技术史",

"藏医学",
"小学英语教育",
"航空物流管理",
"铁道工程技术",
"图文信息处理",
"经济学类",

"日语语言文学",
"城市轨道交通通信信号技术",
"中医骨伤",
"环境规划与管理",
"临床与咨询",
"智慧健康养老服务与管理",


"交通管理工程",
"养老服务管理",
"智能装备与系统",
"大数据与审计",
"虚拟现实技术",
"学科教学(思政)",

"粮食工程技术与管理",
"传播与策划",
"铁路通信与信息化技术",
"机电设备技术",
"司法鉴定学",
"中西医结合影像学",
"汽车工程技术",

"铁路物流管理",
"水生生物学",
"能源经济",
"智慧健康服务与管理",
"321321",
"新能源装备技术",

"武术名族传统与体育",
"智慧农业",
"软件工程技术",
"机械电子技术",
"缅甸语",
"新工科求真实验班",

"医疗产品管理",
"智慧旅游技术应用",
"保密管理",
"核物理",
"生物制药技术",
"时尚传播",

"计算机艺术设计",
"体育人文社会学",
"航空宇航科学与技术",
"教育与康养",
"小学数学教育",
"水产养殖技术",
"输配电工程技术",

"电脑学",
"海外安全管理",
"智能制造工程技术",
"现代分析测试技术",
"国际经济与贸易专业",
"集成电路技术"
]


class PowerCrawler:
    """专门用于展开按钮的爬虫"""
    
    def __init__(self, headless: bool = True, output_dir: str = None):
        self.headless = headless
        self.output_dir = output_dir
        
    async def crawl_with_expand_buttons(self, url: str) -> bool:
        """爬取并点击所有展开按钮"""
        try:
            # 配置浏览器
            browser_config = BrowserConfig(
                browser_type="chromium",
                headless=self.headless,
                verbose=True,
                java_script_enabled=True
            )
            
            async with AsyncWebCrawler(config=browser_config) as crawler:
                print(f"正在爬取: {url}")
                print(f"浏览器模式: {'有头模式' if not self.headless else '无头模式'}")
                print("开始点击所有展开按钮...")
                
                # 第一轮：点击所有展开按钮
                js_commands = [
                    "window.scrollTo(0, document.body.scrollHeight);",
                    # 查找并点击所有包含"展开"的按钮
                    """
                    const expandButtons = Array.from(document.querySelectorAll('button, a, span, div')).filter(el => {
                        const text = el.textContent || el.innerText || '';
                        return text.includes('展开') || text.includes('展开更多') || text.includes('显示更多');
                    });
                    console.log('找到展开按钮数量:', expandButtons.length);
                    expandButtons.forEach((btn, index) => {
                        if (btn.offsetParent !== null && btn.style.display !== 'none') {
                            btn.click();
                            console.log('点击了第', index + 1, '个展开按钮');
                        }
                    });
                    """
                ]
                
                config = CrawlerRunConfig(
                    js_code=js_commands, 
                    session_id="kkdaxue_session",
                    wait_for_timeout=10000,
                    delay_before_return_html=5.0
                )
                
                print("执行第一轮展开...")
                result = await crawler.arun(url=url, config=config)
                
                if not result or not result.markdown:
                    print("第一轮爬取失败")
                    return False
                
                print(f"第一轮完成，内容长度: {len(result.markdown)} 字符")
                
                # 等待一下让内容加载
                await asyncio.sleep(5)
                
                # 第二轮：再次点击可能新出现的展开按钮，使用相同的session_id
                js_commands_round2 = [
                    "window.scrollTo(0, document.body.scrollHeight);",
                    # 第二轮查找并点击展开按钮
                    """
                    const expandButtons2 = Array.from(document.querySelectorAll('button, a, span, div')).filter(el => {
                        const text = el.textContent || el.innerText || '';
                        return text.includes('展开') || text.includes('展开更多') || text.includes('显示更多');
                    });
                    console.log('第二轮找到展开按钮数量:', expandButtons2.length);
                    expandButtons2.forEach((btn, index) => {
                        if (btn.offsetParent !== null && btn.style.display !== 'none') {
                            btn.click();
                            console.log('第二轮点击了第', index + 1, '个展开按钮');
                        }
                    });
                    """
                ]
                
                config2 = CrawlerRunConfig(
                    js_code=js_commands_round2, 
                    session_id="kkdaxue_session",
                    js_only=True,
                    wait_for_timeout=10000,
                    delay_before_return_html=5.0
                )
                
                print("执行第二轮展开...")
                result2 = await crawler.arun(url=url, config=config2)
                
                if not result2 or not result2.markdown:
                    print("第二轮爬取失败")
                    return False
                
                print(f"第二轮完成，内容长度: {len(result2.markdown)} 字符")
                
                # 第三轮：最后一次尝试展开，使用相同的session_id
                js_commands_round3 = [
                    "window.scrollTo(0, document.body.scrollHeight);",
                    # 第三轮查找并点击展开按钮
                    """
                    const expandButtons3 = Array.from(document.querySelectorAll('button, a, span, div')).filter(el => {
                        const text = el.textContent || el.innerText || '';
                        return text.includes('展开') || text.includes('展开更多') || text.includes('显示更多');
                    });
                    console.log('第三轮找到展开按钮数量:', expandButtons3.length);
                    expandButtons3.forEach((btn, index) => {
                        if (btn.offsetParent !== null && btn.style.display !== 'none') {
                            btn.click();
                            console.log('第三轮点击了第', index + 1, '个展开按钮');
                        }
                    });
                    """
                ]
                
                config3 = CrawlerRunConfig(
                    js_code=js_commands_round3, 
                    session_id="kkdaxue_session",
                    js_only=True,
                    wait_for_timeout=10000,
                    delay_before_return_html=5.0
                )
                
                print("执行第三轮展开...")
                result3 = await crawler.arun(url=url, config=config3)
                
                if not result3 or not result3.markdown:
                    print("第三轮爬取失败")
                    return False
                
                print(f"第三轮完成，内容长度: {len(result3.markdown)} 字符")
                
                # 保存最终结果到指定文件夹
                if self.output_dir:
                    # 生成文件名，使用URL的页码信息
                    page_num = url.split('current=')[-1] if 'current=' in url else 'unknown'
                    filename = f"page_{page_num}_fully_expanded.md"
                    filepath = os.path.join(self.output_dir, filename)
                    
                    with open(filepath, 'w', encoding='utf-8') as f:
                        f.write(f"# {getattr(result3, 'title', 'N/A')}\n\n")
                        f.write(f"URL: {result3.url}\n\n")
                        f.write(f"页码: {page_num}\n\n")
                        f.write("---\n\n")
                        f.write(str(result3.markdown))
                    
                    print(f"已保存到: {filepath}")
                    print(f"最终内容长度: {len(result3.markdown)} 字符")
                
                return True
                
        except Exception as e:
            print(f"爬取失败: {e}")
            return False


async def main():
    """主函数"""
    # 创建唯一的输出文件夹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    unique_id = str(uuid.uuid4())[:8]  # 使用UUID的前8位
    output_dir = f"crawl_results_{timestamp}_{unique_id}"
    
    # 确保文件夹存在
    os.makedirs(output_dir, exist_ok=True)
    print(f"创建输出文件夹: {output_dir}")
    
    # 保存任务信息
    task_info_file = os.path.join(output_dir, "task_info.txt")
    with open(task_info_file, 'w', encoding='utf-8') as f:
        f.write(f"爬取任务开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"输出文件夹: {output_dir}\n")
        f.write(f"任务ID: {unique_id}\n\n")
    
    print(f"任务信息已保存到: {task_info_file}")

    # 爬取多个页面
    for i in range(1, 986):
        url = f"https://www.kkdaxue.com/?current={i}"
        print(f"\n{'='*50}")
        print(f"开始爬取第 {i} 页: {url}")
        print(f"{'='*50}")
        
        crawler = PowerCrawler(headless=False, output_dir=output_dir)
        success = await crawler.crawl_with_expand_buttons(url)
        
        if success:
            print(f"第 {i} 页爬取完成!")
        else:
            print(f"第 {i} 页爬取失败!")
    
    # 保存任务完成信息
    completion_info_file = os.path.join(output_dir, "completion_info.txt")
    with open(completion_info_file, 'w', encoding='utf-8') as f:
        f.write(f"爬取任务完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"输出文件夹: {output_dir}\n")
        f.write(f"任务ID: {unique_id}\n")
    
    print(f"\n{'='*50}")
    print(f"所有页面爬取完成!")
    print(f"结果保存在文件夹: {output_dir}")
    print(f"任务完成信息: {completion_info_file}")
    print(f"{'='*50}")


async def main_major():
    """主函数"""
    # 创建唯一的输出文件夹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    unique_id = str(uuid.uuid4())[:8]  # 使用UUID的前8位
    output_dir = f"crawl_results_{timestamp}_{unique_id}"
    
    # 确保文件夹存在
    os.makedirs(output_dir, exist_ok=True)
    print(f"创建输出文件夹: {output_dir}")
    
    # 保存任务信息
    task_info_file = os.path.join(output_dir, "task_info.txt")
    with open(task_info_file, 'w', encoding='utf-8') as f:
        f.write(f"爬取任务开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"输出文件夹: {output_dir}\n")
        f.write(f"任务ID: {unique_id}\n\n")
    
    print(f"任务信息已保存到: {task_info_file}")



    #"https://www.kkdaxue.com/?current=1&major=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF&pageSize=10&sortField=createTime&sortOrder=descend"

    # 爬取多个页面
    majors_with_no_data = []  # 存储没有数据的专业
    
    for major in majors:
        print(f"\n{'='*50}")
        print(f"开始爬取专业: {major}")
        print(f"{'='*50}")
        
        i = 1  # 从第1页开始
        has_data = True  # 标记该专业是否还有数据
        
        while has_data:
            url = f"https://www.kkdaxue.com/?current={i}&major={major}&pageSize=10&sortField=createTime&sortOrder=descend"
            print(f"\n开始爬取第 {i} 页: {url}")
            
            crawler = PowerCrawler(headless=False, output_dir=output_dir)
            success = await crawler.crawl_with_expand_buttons(url)
            
            if success:
                # 检查爬取的内容是否包含"暂无数据"
                # 读取最新爬取的文件内容
                try:
                    # 查找该专业第i页的爬取结果文件
                    page_files = [f for f in os.listdir(output_dir) if f.startswith(f"page_{i}_") and major in f]
                    if page_files:
                        latest_file = os.path.join(output_dir, page_files[0])
                        with open(latest_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        if "暂无数据" in content:
                            print(f"第 {i} 页发现'暂无数据'，专业 {major} 爬取完成")
                            has_data = False
                            
                            # 如果是第1页就没有数据，记录该专业
                            if i == 1:
                                majors_with_no_data.append(major)
                                print(f"专业 {major} 第1页就没有数据，已记录")
                        else:
                            print(f"第 {i} 页爬取完成，继续下一页")
                            i += 1
                    else:
                        print(f"未找到第 {i} 页的爬取结果文件")
                        has_data = False
                        
                except Exception as e:
                    print(f"检查页面内容时出错: {e}")
                    has_data = False
            else:
                print(f"第 {i} 页爬取失败!")
                has_data = False
        
        print(f"专业 {major} 爬取完成，共爬取 {i-1} 页")
    
    # 保存没有数据的专业到文件
    if majors_with_no_data:
        no_data_file = os.path.join(output_dir, "majors_with_no_data.txt")
        with open(no_data_file, 'w', encoding='utf-8') as f:
            f.write(f"没有数据的专业列表\n")
            f.write(f"记录时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"专业数量: {len(majors_with_no_data)}\n")
            f.write(f"{'='*50}\n\n")
            
            for i, major in enumerate(majors_with_no_data, 1):
                f.write(f"{i:3d}. {major}\n")
        
        # 保存为Python列表格式
        no_data_python_file = os.path.join(output_dir, "majors_with_no_data.py")
        with open(no_data_python_file, 'w', encoding='utf-8') as f:
            f.write("# 没有数据的专业列表\n")
            f.write("majors_with_no_data = [\n")
            for major in majors_with_no_data:
                f.write(f'    "{major}",\n')
            f.write("]\n\n")
            f.write(f"# 总数: {len(majors_with_no_data)}\n")
        
        print(f"\n没有数据的专业已保存到:")
        print(f"  - 文本格式: {no_data_file}")
        print(f"  - Python列表: {no_data_python_file}")
        print(f"  - 专业数量: {len(majors_with_no_data)}")
    else:
        print(f"\n所有专业都有数据，没有记录到'暂无数据'的专业")
    
    # 保存任务完成信息
    completion_info_file = os.path.join(output_dir, "completion_info.txt")
    with open(completion_info_file, 'f') as f:
        f.write(f"爬取任务完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"输出文件夹: {output_dir}\n")
        f.write(f"任务ID: {unique_id}\n")
        f.write(f"总专业数: {len(majors)}\n")
        f.write(f"无数据专业数: {len(majors_with_no_data)}\n")
        if majors_with_no_data:
            f.write(f"无数据专业列表: {', '.join(majors_with_no_data)}\n")
    
    print(f"\n{'='*50}")
    print(f"所有专业爬取完成!")
    print(f"结果保存在文件夹: {output_dir}")
    print(f"任务完成信息: {completion_info_file}")
    print(f"{'='*50}")




if __name__ == "__main__":
    asyncio.run(main_major())
